import streamlit as st
import os
import tempfile
import json
import shutil
from agent.core import get_agent_executor
from agent.tools import set_current_segy_path, set_current_miniseed_path, set_current_hdf5_path
from langchain_core.messages import HumanMessage, AIMessage


def format_intermediate_steps(intermediate_steps):
    """Turn LangChain intermediate steps into markdown for display."""
    if not intermediate_steps:
        return "ï¼ˆæœ¬æ¬¡æ²¡æœ‰è°ƒç”¨å·¥å…·ï¼‰"

    blocks = []
    for idx, (action, observation) in enumerate(intermediate_steps, start=1):
        tool_input = action.tool_input
        if isinstance(tool_input, dict):
            tool_input_str = json.dumps(tool_input, ensure_ascii=False)
        else:
            tool_input_str = str(tool_input)

        block = (
            f"{idx}. **å·¥å…·** `{action.tool}`\n"
            f"   - è¾“å…¥: `{tool_input_str}`\n"
            f"   - è§‚å¯Ÿ: {observation}"
        )
        blocks.append(block)

    return "\n\n".join(blocks)

# Page Config
st.set_page_config(page_title="QuakeCore AI Agent", layout="wide")

st.title("ğŸŒ‹ QuakeCore AI - åœ°éœ‡æ•°æ®æ™ºèƒ½åŠ©æ‰‹")

# Initialize Session State
if "messages" not in st.session_state:
    st.session_state.messages = []

if "agent" not in st.session_state:
    st.session_state.agent = None

if "agent_config" not in st.session_state:
    st.session_state.agent_config = None

if "agent_error" not in st.session_state:
    st.session_state.agent_error = None
if "uploaded_filename" not in st.session_state:
    st.session_state.uploaded_filename = None
if "current_file_ext" not in st.session_state:
    st.session_state.current_file_ext = None

with st.sidebar:
    st.header("æ¨¡å‹é…ç½®")
    provider_options = {
        "DeepSeek API": "deepseek",
        "æœ¬åœ° Ollama": "ollama",
    }
    provider_label = st.selectbox("é€‰æ‹©æ¨ç†å¼•æ“", list(provider_options.keys()), index=0, key="provider_select")
    provider = provider_options[provider_label]

    current_agent_config = {}
    if provider == "ollama":
        model_name = st.text_input("æœ¬åœ°æ¨¡å‹åç§° (Ollama)", value="qwen2.5:3b", key="ollama_model_input")
        st.info("è¯·ç¡®ä¿æœ¬åœ°å·²å®‰è£… Ollama å¹¶è¿è¡Œäº†å¯¹åº”æ¨¡å‹")
        current_agent_config = {
            "provider": "ollama",
            "model_name": model_name,
            "api_key": None,
            "base_url": None,
        }
    else:
        deepseek_model = st.text_input("DeepSeek æ¨¡å‹åç§°", value="deepseek-chat", key="deepseek_model_input")
        deepseek_api_key = st.text_input(
            "DeepSeek API Key",
            value=os.getenv("DEEPSEEK_API_KEY", ""),
            type="password",
            key="deepseek_api_key_input",
        )
        deepseek_base_url = st.text_input(
            "DeepSeek Base URL",
            value="https://api.deepseek.com",
            key="deepseek_base_url_input",
        )
        current_agent_config = {
            "provider": "deepseek",
            "model_name": deepseek_model,
            "api_key": deepseek_api_key,
            "base_url": deepseek_base_url,
        }
        st.info("ä½¿ç”¨ DeepSeek æ—¶éœ€è¦æœ‰æ•ˆçš„ API Keyï¼Œå¯åœ¨ç¯å¢ƒå˜é‡ DEEPSEEK_API_KEY ä¸­é…ç½®ã€‚")

config_changed = current_agent_config != st.session_state.agent_config
if config_changed:
    if current_agent_config["provider"] == "deepseek" and not current_agent_config.get("api_key"):
        st.session_state.agent = None
        st.session_state.agent_config = None
        st.session_state.agent_error = "DeepSeek æ¨¡å¼éœ€è¦æä¾› API Keyã€‚"
    else:
        try:
            st.session_state.agent = get_agent_executor(**current_agent_config)
            st.session_state.agent_config = current_agent_config
            st.session_state.agent_error = None
        except Exception as err:
            st.session_state.agent = None
            st.session_state.agent_config = None
            st.session_state.agent_error = str(err)

agent_error = st.session_state.agent_error
agent_ready = st.session_state.agent is not None

if agent_error:
    st.error(agent_error)
elif not agent_ready:
    st.info("è¯·åœ¨ä¾§è¾¹æ å®Œæˆæ¨¡å‹é…ç½®ä»¥å¯åŠ¨å¯¹è¯ã€‚")

# Attachment upload near chat
uploaded_file_main = st.file_uploader(
    "ä¸Šä¼ æ•°æ®æ–‡ä»¶ï¼ˆSEGY/SGY/MiniSEED/HDF5ï¼‰",
    type=["segy", "sgy", "mseed", "miniseed","h5","hdf5"],
    help="é€‰æ‹©å•ä¸ªæ–‡ä»¶å¹¶å¤åˆ¶åˆ° data ç›®å½•"
)

if uploaded_file_main:
    filename = uploaded_file_main.name
    ext = os.path.splitext(filename)[1].lower().lstrip(".")
    data_dir = os.path.join(os.getcwd(), "data")
    os.makedirs(data_dir, exist_ok=True)
    target_path = os.path.join(data_dir, filename)
    with open(target_path, "wb") as f:
        f.write(uploaded_file_main.getvalue())
    st.session_state.current_file_path = target_path
    st.session_state.uploaded_filename = filename
    st.session_state.current_file_ext = ext
    st.success(f"æ–‡ä»¶å·²å¤åˆ¶åˆ° data: `{filename}`")

if "current_file_path" in st.session_state:
    ext = st.session_state.get("current_file_ext")
    if ext in {"segy", "sgy"}:
        set_current_segy_path(st.session_state.current_file_path)
    elif ext in {"mseed", "miniseed"}:
        set_current_miniseed_path(st.session_state.current_file_path)
    elif ext in {"h5","hdf5"}:
        set_current_hdf5_path(st.session_state.current_file_path)

# Chat Interface
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        if steps := message.get("steps"):
            with st.expander("æ€è€ƒè¿‡ç¨‹", expanded=False):
                st.markdown(steps)

# User Input
prompt = st.chat_input(
    "è¾“å…¥ä½ çš„é—®é¢˜ï¼ˆå¯å…ˆåœ¨ä¸Šæ–¹ä¸Šä¼ æ–‡ä»¶ï¼‰",
    disabled=not agent_ready,
)

if prompt and agent_ready:
    # Display user message
    st.chat_message("user").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    # Generate response
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        message_placeholder.markdown("æ€è€ƒä¸­...")
        
        try:
            # Prepare chat history for LangChain
            chat_history = []
            for msg in st.session_state.messages[:-1]: # Exclude current prompt
                if msg["role"] == "user":
                    chat_history.append(HumanMessage(content=msg["content"]))
                else:
                    chat_history.append(AIMessage(content=msg["content"]))
            
            # Run Agent
            response = st.session_state.agent.invoke({
                "input": prompt,
                "chat_history": chat_history
            })
            
            answer = response["output"]
            steps_markdown = format_intermediate_steps(response.get("intermediate_steps", []))

            message_placeholder.markdown(answer)
            with st.expander("æ€è€ƒè¿‡ç¨‹", expanded=False):
                st.markdown(steps_markdown)

            st.session_state.messages.append({
                "role": "assistant",
                "content": answer,
                "steps": steps_markdown
            })
            
        except Exception as e:
            active_provider = (st.session_state.agent_config or current_agent_config or {}).get("provider", "ollama")
            provider_hint = "Ollama æœ¬åœ°æœåŠ¡" if active_provider == "ollama" else "DeepSeek API é…ç½®æˆ–ç½‘ç»œçŠ¶æ€"
            error_msg = f"å‘ç”Ÿé”™è¯¯: {str(e)}\n\nè¯·æ£€æŸ¥ {provider_hint}ã€‚"
            message_placeholder.error(error_msg)
            st.session_state.messages.append({"role": "assistant", "content": error_msg})

# Cleanup on exit (Optional - Streamlit handles temp files differently depending on OS, 
# but explicit cleanup is good practice if we were managing sessions manually)
